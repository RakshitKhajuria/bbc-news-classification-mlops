{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import sys\n",
    "\n",
    "def preprocessDataset(train_text):\n",
    "  \n",
    "       \n",
    "        #word tokenization using text-to-word-sequence\n",
    "        train_text= str(train_text)\n",
    "        tokenized_train_set = text_to_word_sequence(train_text,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True,split=\" \")\n",
    "            \n",
    "        #stop word removal\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        stopwordremove = [i for i in tokenized_train_set if not i in stop_words]\n",
    "            \n",
    "        \n",
    "        #join words into sentence\n",
    "        stopwordremove_text = ' '.join(stopwordremove)\n",
    "            \n",
    "            \n",
    "        #remove numbers\n",
    "        numberremove_text = ''.join(c for c in stopwordremove_text if not c.isdigit())\n",
    "        \n",
    "            \n",
    "        #--Stemming--\n",
    "        stemmer= PorterStemmer()\n",
    "\n",
    "        stem_input=nltk.word_tokenize(numberremove_text)\n",
    "        stem_text=' '.join([stemmer.stem(word) for word in stem_input])\n",
    "            \n",
    "            \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        def get_wordnet_pos(word):\n",
    "            \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "            tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "            tag_dict = {\"J\": wordnet.ADJ,\n",
    "                    \"N\": wordnet.NOUN,\n",
    "                    \"V\": wordnet.VERB,\n",
    "                    \"R\": wordnet.ADV}\n",
    "\n",
    "            return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "        lem_input = nltk.word_tokenize(stem_text)\n",
    "        lem_text= ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in lem_input])\n",
    "            \n",
    "        return lem_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_categorical(column):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(column)\n",
    "    encoded = le.transform(column)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "df=pd.read_csv(\"data\\BBC News Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ArticleId', 'Text', 'Category'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category=encode_categorical(df[\"Category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 4, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_Text'] = df['Text'].apply(preprocessDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english') #tfidfVectorizer\n",
    "X = tfidf_vect.fit_transform(df[\"Clean_Text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 8544)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 4.],\n",
       "       [0., 0., 0., ..., 0., 0., 4.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.c_[X.toarray(), category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_csv(r\"D:\\full_stack\\MyPractice\\ml_project_cicd\\project2\\bbc-news-classification-mlops\\artifacts\\train.csv\")\n",
    "train=train.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import sys\n",
    "\n",
    "def preprocessDataset(train_text):\n",
    "    \n",
    "       \n",
    "        #word tokenization using text-to-word-sequence\n",
    "        train_text= str(train_text)\n",
    "        tokenized_train_set = text_to_word_sequence(train_text,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True,split=\" \")\n",
    "            \n",
    "        #stop word removal\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        stopwordremove = [i for i in tokenized_train_set if not i in stop_words]\n",
    "            \n",
    "        \n",
    "        #join words into sentence\n",
    "        stopwordremove_text = ' '.join(stopwordremove)\n",
    "            \n",
    "            \n",
    "        #remove numbers\n",
    "        numberremove_text = ''.join(c for c in stopwordremove_text if not c.isdigit())\n",
    "        \n",
    "            \n",
    "        #--Stemming--\n",
    "        stemmer= PorterStemmer()\n",
    "\n",
    "        stem_input=nltk.word_tokenize(numberremove_text)\n",
    "        stem_text=' '.join([stemmer.stem(word) for word in stem_input])\n",
    "            \n",
    "            \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        def get_wordnet_pos(word):\n",
    "            \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "            tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "            tag_dict = {\"J\": wordnet.ADJ,\n",
    "                    \"N\": wordnet.NOUN,\n",
    "                    \"V\": wordnet.VERB,\n",
    "                    \"R\": wordnet.ADV}\n",
    "\n",
    "            return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "        lem_input = nltk.word_tokenize(stem_text)\n",
    "        lem_text= ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in lem_input])\n",
    "            \n",
    "        return lem_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train[\"c\"]=preprocessDataset(train[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1330</td>\n",
       "      <td>irish finish with home game republic of irelan...</td>\n",
       "      <td>sport</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111</td>\n",
       "      <td>what high-definition will do to dvds first it ...</td>\n",
       "      <td>tech</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1273</td>\n",
       "      <td>vera drake s bafta triumph hope at the bafta f...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>174</td>\n",
       "      <td>commons hunt protest charges eight protesters ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>605</td>\n",
       "      <td>da vinci code is  lousy history  the plot of a...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1112</td>\n",
       "      <td>eu referendum question unveiled the question t...</td>\n",
       "      <td>politics</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>197</td>\n",
       "      <td>versace art portfolio up for sale the art coll...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1838</td>\n",
       "      <td>watchdog probes e-mail deletions the informati...</td>\n",
       "      <td>politics</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1380</td>\n",
       "      <td>dibaba breaks 5 000m world record ethiopia s t...</td>\n",
       "      <td>sport</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>318</td>\n",
       "      <td>uk debut for kevin spacey movie hollywood star...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ArticleId                                               Text  \\\n",
       "0        1330  irish finish with home game republic of irelan...   \n",
       "1        1111  what high-definition will do to dvds first it ...   \n",
       "2        1273  vera drake s bafta triumph hope at the bafta f...   \n",
       "3         174  commons hunt protest charges eight protesters ...   \n",
       "4         605  da vinci code is  lousy history  the plot of a...   \n",
       "..        ...                                                ...   \n",
       "95       1112  eu referendum question unveiled the question t...   \n",
       "96        197  versace art portfolio up for sale the art coll...   \n",
       "97       1838  watchdog probes e-mail deletions the informati...   \n",
       "98       1380  dibaba breaks 5 000m world record ethiopia s t...   \n",
       "99        318  uk debut for kevin spacey movie hollywood star...   \n",
       "\n",
       "         Category                                                  c  \n",
       "0           sport  irish finish home game republ irelan high defi...  \n",
       "1            tech  irish finish home game republ irelan high defi...  \n",
       "2   entertainment  irish finish home game republ irelan high defi...  \n",
       "3        politics  irish finish home game republ irelan high defi...  \n",
       "4   entertainment  irish finish home game republ irelan high defi...  \n",
       "..            ...                                                ...  \n",
       "95       politics  irish finish home game republ irelan high defi...  \n",
       "96  entertainment  irish finish home game republ irelan high defi...  \n",
       "97       politics  irish finish home game republ irelan high defi...  \n",
       "98          sport  irish finish home game republ irelan high defi...  \n",
       "99  entertainment  irish finish home game republ irelan high defi...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_csv(r\"D:\\full_stack\\MyPractice\\ml_project_cicd\\project2\\bbc-news-classification-mlops\\artifacts\\clean_train.csv\")\n",
    "train=train.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "def load_object(file_path):\n",
    "    \n",
    "        with open(file_path, \"rb\") as file_obj:\n",
    "            return dill.load(file_obj)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_path='artifacts/proprocessor.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"New Zealand completed an innings and 58-run victory over Sri Lanka in the second Test in blustery Wellington on Monday to sweep the series 2-0 as the South Asian side's resistance finally broke late on day four. Having been asked to follow on, Sri Lanka needed 416 runs to make the hosts bat again but were bowled out for 358 in their second innings at the Basin Reserve. New Zealand completed their third Test win in succession after claiming the thrilling series-opener by two wickets on the last ball in Christchurch and beating England by one run in another cliffhanger in Wellington. Sri Lanka's hopes of a first win in the country since 2006 all but ended when their batters managed only 164 in reply to New Zealand's declared first innings total of 580 for four.\"\n",
    "clean_text=preprocessDataset(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"new zealand complet inning run victori sri lanka second test blusteri wellington monday sweep seri south asian side 's resist final broke late day four ask follow sri lanka need run make host bat bowl second inning basin reserv new zealand complet third test win success claim thrill seri open two wicket last ball christchurch beat england one run anoth cliffhang wellington sri lanka 's hope first win countri sinc end batter manag repli new zealand 's declar first inning total four\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor=load_object(r\"D:\\full_stack\\MyPractice\\ml_project_cicd\\project2\\bbc-news-classification-mlops\\artifacts\\proprocessor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_text=preprocessor.transform(list(clean_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'bbc' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n bbc ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_csv(r\"D:\\full_stack\\MyPractice\\ml_project_cicd\\project2\\bbc-news-classification-mlops\\artifacts\\train.csv\")\n",
    "train=train.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'bbc' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n bbc ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
