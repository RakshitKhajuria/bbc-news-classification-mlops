{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import sys\n",
    "\n",
    "def preprocessDataset(train_text):\n",
    "  \n",
    "       \n",
    "        #word tokenization using text-to-word-sequence\n",
    "        train_text= str(train_text)\n",
    "        tokenized_train_set = text_to_word_sequence(train_text,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True,split=\" \")\n",
    "            \n",
    "        #stop word removal\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        stopwordremove = [i for i in tokenized_train_set if not i in stop_words]\n",
    "            \n",
    "        \n",
    "        #join words into sentence\n",
    "        stopwordremove_text = ' '.join(stopwordremove)\n",
    "            \n",
    "            \n",
    "        #remove numbers\n",
    "        numberremove_text = ''.join(c for c in stopwordremove_text if not c.isdigit())\n",
    "        \n",
    "            \n",
    "        #--Stemming--\n",
    "        stemmer= PorterStemmer()\n",
    "\n",
    "        stem_input=nltk.word_tokenize(numberremove_text)\n",
    "        stem_text=' '.join([stemmer.stem(word) for word in stem_input])\n",
    "            \n",
    "            \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        def get_wordnet_pos(word):\n",
    "            \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "            tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "            tag_dict = {\"J\": wordnet.ADJ,\n",
    "                    \"N\": wordnet.NOUN,\n",
    "                    \"V\": wordnet.VERB,\n",
    "                    \"R\": wordnet.ADV}\n",
    "\n",
    "            return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "        lem_input = nltk.word_tokenize(stem_text)\n",
    "        lem_text= ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in lem_input])\n",
    "            \n",
    "        return lem_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_categorical(column):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(column)\n",
    "    encoded = le.transform(column)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "df=pd.read_csv(\"data\\BBC News Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ArticleId', 'Text', 'Category'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category=encode_categorical(df[\"Category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 4, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_Text'] = df['Text'].apply(preprocessDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english') #tfidfVectorizer\n",
    "X = tfidf_vect.fit_transform(df[\"Clean_Text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 8544)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 4.],\n",
       "       [0., 0., 0., ..., 0., 0., 4.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.c_[X.toarray(), category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_csv(r\"D:\\full_stack\\MyPractice\\ml_project_cicd\\project2\\bbc-news-classification-mlops\\artifacts\\train.csv\")\n",
    "train=train.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import sys\n",
    "\n",
    "def preprocessDataset(train_text):\n",
    "    \n",
    "       \n",
    "        #word tokenization using text-to-word-sequence\n",
    "        train_text= str(train_text)\n",
    "        tokenized_train_set = text_to_word_sequence(train_text,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True,split=\" \")\n",
    "            \n",
    "        #stop word removal\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        stopwordremove = [i for i in tokenized_train_set if not i in stop_words]\n",
    "            \n",
    "        \n",
    "        #join words into sentence\n",
    "        stopwordremove_text = ' '.join(stopwordremove)\n",
    "            \n",
    "            \n",
    "        #remove numbers\n",
    "        numberremove_text = ''.join(c for c in stopwordremove_text if not c.isdigit())\n",
    "        \n",
    "            \n",
    "        #--Stemming--\n",
    "        stemmer= PorterStemmer()\n",
    "\n",
    "        stem_input=nltk.word_tokenize(numberremove_text)\n",
    "        stem_text=' '.join([stemmer.stem(word) for word in stem_input])\n",
    "            \n",
    "            \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        def get_wordnet_pos(word):\n",
    "            \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "            tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "            tag_dict = {\"J\": wordnet.ADJ,\n",
    "                    \"N\": wordnet.NOUN,\n",
    "                    \"V\": wordnet.VERB,\n",
    "                    \"R\": wordnet.ADV}\n",
    "\n",
    "            return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "        lem_input = nltk.word_tokenize(stem_text)\n",
    "        lem_text= ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in lem_input])\n",
    "            \n",
    "        return lem_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train[\"c\"]=preprocessDataset(train[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1330</td>\n",
       "      <td>irish finish with home game republic of irelan...</td>\n",
       "      <td>sport</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111</td>\n",
       "      <td>what high-definition will do to dvds first it ...</td>\n",
       "      <td>tech</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1273</td>\n",
       "      <td>vera drake s bafta triumph hope at the bafta f...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>174</td>\n",
       "      <td>commons hunt protest charges eight protesters ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>605</td>\n",
       "      <td>da vinci code is  lousy history  the plot of a...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1112</td>\n",
       "      <td>eu referendum question unveiled the question t...</td>\n",
       "      <td>politics</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>197</td>\n",
       "      <td>versace art portfolio up for sale the art coll...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1838</td>\n",
       "      <td>watchdog probes e-mail deletions the informati...</td>\n",
       "      <td>politics</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1380</td>\n",
       "      <td>dibaba breaks 5 000m world record ethiopia s t...</td>\n",
       "      <td>sport</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>318</td>\n",
       "      <td>uk debut for kevin spacey movie hollywood star...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>irish finish home game republ irelan high defi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ArticleId                                               Text  \\\n",
       "0        1330  irish finish with home game republic of irelan...   \n",
       "1        1111  what high-definition will do to dvds first it ...   \n",
       "2        1273  vera drake s bafta triumph hope at the bafta f...   \n",
       "3         174  commons hunt protest charges eight protesters ...   \n",
       "4         605  da vinci code is  lousy history  the plot of a...   \n",
       "..        ...                                                ...   \n",
       "95       1112  eu referendum question unveiled the question t...   \n",
       "96        197  versace art portfolio up for sale the art coll...   \n",
       "97       1838  watchdog probes e-mail deletions the informati...   \n",
       "98       1380  dibaba breaks 5 000m world record ethiopia s t...   \n",
       "99        318  uk debut for kevin spacey movie hollywood star...   \n",
       "\n",
       "         Category                                                  c  \n",
       "0           sport  irish finish home game republ irelan high defi...  \n",
       "1            tech  irish finish home game republ irelan high defi...  \n",
       "2   entertainment  irish finish home game republ irelan high defi...  \n",
       "3        politics  irish finish home game republ irelan high defi...  \n",
       "4   entertainment  irish finish home game republ irelan high defi...  \n",
       "..            ...                                                ...  \n",
       "95       politics  irish finish home game republ irelan high defi...  \n",
       "96  entertainment  irish finish home game republ irelan high defi...  \n",
       "97       politics  irish finish home game republ irelan high defi...  \n",
       "98          sport  irish finish home game republ irelan high defi...  \n",
       "99  entertainment  irish finish home game republ irelan high defi...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
